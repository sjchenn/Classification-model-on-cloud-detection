---
title: "STA521_PRO2"
author: "Sijie Chen"
date: "10/31/2021"
output: html_document
---

```{r}
library(tidyverse)
library(ggplot2)
library(tidyverse)
library(reshape)
library(GGally)
library(DiscriMiner)
library(gridExtra)
library(caret)
library(glmnet)
library(corrplot)
```


#1 Data Collection and Exploration

```{r}
#load data
image1 <- read.csv('imagem1.txt',sep='',header=FALSE)
image2 <- read.csv('imagem2.txt', sep='',header=FALSE)
image3 <- read.csv('imagem3.txt', sep='',header=FALSE)

vcol <- c('y','x','expert_labels','NDAI','SD','CORR','DF','CF','BF','AF','AN')



colnames(image1) <- vcol
colnames(image2) <- vcol
colnames(image3) <- vcol

# combine all three datasets
image <- rbind(image1,image2,image3)
```



## (b)
According to the heat map, we can observe patterns between xy coordinates and expert labels. The majority of unlabeled pixels are around x coordinates near 300. Furthermore, we can clearly see that the closer the geological location of the pixels are, they are more likely to share same label. Therefore, our assumption of independent and identical distributed doesn't hold for this data set. 
```{r}
#summarize the data
table(image$expertlabels)
ggplot(data=image,aes(x=x,y=y,fill=expert_labels))+
  geom_tile()+
  ggtitle('Heat Map With Exexpert Labels')
```

## (c) Perform visual and quantitative and visual EDA
### pairwise relationships
```{r}
#image %>% 
  #select(NDAI,SD,CORR,DF,CF,BF,AF,AN) %>% 
  #ggpairs()
```
Among all eight feature correlation, we found that there are seven pairs correlations between features are higher than $0.7$. 
```{r}
imagefeature <- image %>% 
  select(NDAI,SD,CORR,DF,CF,BF,AF,AN)
feature_cor <- cor(imagefeature)
for (i in 1:nrow(feature_cor)){
    correlations <-  which((abs(feature_cor[i,i:ncol(feature_cor)]) > 0.7) & (feature_cor[i,i:ncol(feature_cor)] != 1))
    if(length(correlations)> 0){
      lapply(correlations,FUN =  function(x) (cat(paste(colnames(feature_cor)[i], "with",colnames(feature_cor)[x]), "\n")))
    }
  }
```
### pairwise relationships between expert labels and individual features.

We suspects that the underlying relationship between expert labels and individual features are not linear. For better estimation on correlation between continuous variable and categorical variable, we used correlation ration. According to the quantitative result, NDAI and CORR have highest correlation with expert labels. SD togther with radiance angle AF and AN approximately have equal correlation with expert labels that is around $0.15$.

```{r}
for (i in 1:ncol(imagefeature)){
  print(corRatio(imagefeature[,i],image$expert_labels))
}
```
According to visualization, distribution of features with highest five correlation ratio under three labels are distinct meaning those features are valuable when we creating the model. 
```{r}
#change expertlabels into factors
image <- image %>% 
  mutate(expertlabels=as.factor(expert_labels))
#visualization on correlations
g1 <- ggplot(image,aes(x=NDAI,fill=expert_labels))+
    geom_density(alpha=0.3)
g2 <- ggplot(image,aes(x=SD,fill=expert_labels))+
    geom_density(alpha=0.3)
g3 <- ggplot(image,aes(x=CORR,fill=expert_labels))+
    geom_density(alpha=0.3)
g4 <- ggplot(image,aes(x=AF,fill=expert_labels))+
    geom_density(alpha=0.3)
g5 <- ggplot(image,aes(x=AN,fill=expert_labels))+
    geom_density(alpha=0.3)
grid.arrange(g1,g2,g3,g4,g5,ncol=2)
```

In addition, we want to see the differences between two classes (cloud,no cloud) based on features(CORR,NADI and SD).

```{r}
#specificdf only contains two classes and three features
specificdf <- image %>% 
  select(CORR,NDAI,SD,expert_labels) %>% 
  filter(expert_labels==1|expert_labels==-1)
```

```{r}
sp1 <- ggplot(specificdf,aes(x=CORR,fill=expert_labels))+
  geom_density(alpha=0.3)
sp11 <- sp1+facet_wrap(expert_labels~.)
sp2 <- ggplot(specificdf,aes(x=NDAI,fill=expert_labels))+
  geom_density(alpha=0.3)
sp22 <- sp2+facet_wrap(expert_labels~.)
sp3 <- ggplot(specificdf,aes(x=SD,fill=expert_labels))+
  geom_density(alpha=0.3)
sp33 <- sp3+facet_wrap(expert_labels~.)

grid.arrange(sp11,sp22,sp33)
```

According to summary statistics for features CORR, NDAI and SD grouped by expert labels, for pixels labeled as cloud, on average, the pixel data point has higher CORR, NDAI and SD. This fact agrees with our previous visualization which mode of three features in cloud group are statistically larger than modes in no cloud group. 

```{r}
#quant
specificdf %>% 
  group_by(expert_labels) %>% 
  summarize(meanCORR = mean(CORR), meanNDAI= mean(NDAI), meanSD= mean(SD),
            sdCORR = sd(CORR), sdNDAI= sd(NDAI), sdSD= sd(SD))
```


# 2 Preparation

## (a) Train Test Split
```{r}
df <- rbind(image1,image2,image3)
data = df%>%filter(expert_labels != 0)
```


```{r}
# split along y 
data <- data%>%mutate(block_y = ((y-1)%%10)+1)
train_index = sample(1:10,8)
train_data = data%>%filter(block_y %in% train_index)
test_data = data%>%filter(!(block_y %in% train_index))
validation_index = sample(train_index,1)
validation_data = train_data%>%filter(block_y %in%validation_index)
train_data

# split along x
data = df%>%filter(expert_labels != 0)
data <- data%>%mutate(block_x = ((x-64)%%10)+1)
train_index = sample(1:10,8)
train_data = data%>%filter(block_x %in% train_index)
test_data = data%>%filter(!(block_x %in% train_index))
validation_index = sample(train_index,1)
validation_data = train_data%>%filter(block_x %in%validation_index)


# block separation
data = df%>%filter(expert_labels != 0)
data <- data%>%mutate(block_y = ((y-1)%%10)+1,block_x = ((x-64)%%10)+1)%>%mutate(block_index = (block_y-1)*10+block_x)
table(data$block_index)
train_index = sample(1:100,80)
train_data = data%>%filter(block_index %in% train_index)
test_data = data%>%filter(!(block_index %in% train_index))
validation_index = sample(train_index,10)
validation_data = train_data%>%filter(block_index %in%validation_index)
```



# b 
```{r}
# test classifications error 
sum(test_data$expert_labels == -1)/length(test_data$expert_labels)
# validation classifications error
sum(validation_data$expert_labels == -1)/length(test_data$expert_labels)
1 - sum(validation_data$expert_labels == -1)/length(test_data$expert_labels)
```

# c
In order to check important variables associated with expert_labels, we can use a logistic regression. 
```{r}
featuredf <- select(train_data,-c(x,y,block_y,block_x,block_index))
#label = 1 refers to cloud, 0 refers to no cloud
featuredf$expert_labels <- ifelse(featuredf$expert_labels==1,1,0)

logit <- glm(expert_labels~.,data=featuredf,family='binomial')
#xtest <- data.matrix(subset(featuredf,select=-c(expert_labels)))
#ytest <- data.matrix(subset(featuredf,select=c(expert_labels)))
#logit <- glmnet(xtest,ytest,family='binomial',alpha=1,lambda=NULL)
```

The logistic model summary output for all features have p value smaller than $0.05$. 
Nevertheless, we can use variable importance function to perform feature selection. As the result of the varImp, we have the highest four variable importance value which are features: NDAI, SD, CORR and DF. 
```{r}
summary(logit)
```

The visualization of correlation matrix conveys the message that the information from different angles are high correlated, which means they are redundant variables. Furthermore, although variable DF shows descent variable importance value, it has a realtively low (close to zero) correlation with expert labels, thus we will exclude the variable from future modeling. 
```{r}
cor(featuredf)
corrplot(cor(featuredf))
```


```{r}
theme_update(plot.title = element_text(hjust = 0.5))
VI <- varImp(logit,scale=FALSE)
ggplot(aes(x=rownames(VI),y=Overall),data=VI)+
  geom_point()+
  ggtitle('Variable Importance Plot')
```

```{r}
#ggplot(featuredf, aes(x=CORR, y=expert_labels)) + 
  #geom_point(alpha=.5) +
  #stat_smooth(method="glm", se=FALSE, method.args = list(family=binomial),
              #col="red", lty=2)
```

